# -*- coding: utf-8 -*-
"""25-26+psl_extraction+GroupA,B.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Et0mSBaKiMdVq_5NIxWTJ2YnFb6Tnwjg
"""

"""
PDF to Excel Extractor for NEET Selection List - FIXED VERSION
Fixed name extraction with combined text parsing and coordinate approach
"""

# Install required libraries
!pip install pdfplumber openpyxl pandas

import pdfplumber
import pandas as pd
import re
from google.colab import files
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import time

# Upload the PDF file
print("Please upload your PDF file:")
uploaded = files.upload()

# Get the filename
pdf_filename = list(uploaded.keys())[0]

# Define x-axis coordinates for all columns
GENDER_X = {'x0': 422.57, 'x1': 427.36}
CAT_X = {'x0': 434.97, 'x1': 456.97}
QUOTA_X = {'x0': 492.56, 'x1': 514.56}
COLLEGE_CODE_X = {'x0': 624.14, 'x1': 643.32}

def extract_column_by_coordinates_fast(words, x0, x1, y_pos, tolerance=5):
    """Fast extraction for a specific column at given y-position"""
    found_words = []

    for word in words:
        word_x0 = word['x0']
        word_x1 = word['x1']
        word_y = word['top']

        # Check if word is in the right row first (faster)
        if abs(word_y - y_pos) > tolerance:
            continue

        # Then check x-coordinate
        if (x0 - tolerance <= word_x0 <= x1 + tolerance) or \
           (x0 - tolerance <= word_x1 <= x1 + tolerance) or \
           (word_x0 <= x0 and word_x1 >= x1):
            found_words.append(word['text'])

    return ' '.join(found_words) if found_words else ''

def extract_name_from_line(line, cet_form):
    """Extract name from text line using parsing"""
    # Remove the known parts (Sr, AIR, NEET_Roll, CET_Form)
    # Format: Sr AIR NEET_Roll CET_Form Name Gender...

    # First, remove the CET_Form from the line
    if cet_form in line:
        parts = line.split(cet_form, 1)
        if len(parts) > 1:
            rest = parts[1].strip()
        else:
            rest = ""
    else:
        # Fallback: try to find the CET_Form position in the line
        parts = line.split()
        if len(parts) > 4:
            rest = ' '.join(parts[4:])
        else:
            rest = ""

    # Now find where the name ends (before Gender M/F)
    name_parts = []
    words = rest.split()

    for word in words:
        # Stop when we encounter gender (M/F)
        if word in ['M', 'F'] and len(word) == 1:
            break
        name_parts.append(word)

    return ' '.join(name_parts)

def extract_name_from_coordinates(words, row_y, cet_form_x1, gender_x0, tolerance=5):
    """Extract name using coordinates between CET Form and Gender columns"""
    name_parts = []

    for word in words:
        word_x0 = word['x0']
        word_x1 = word['x1']
        word_y = word['top']
        word_text = word['text']

        # Check if word is in the right row
        if abs(word_y - row_y) > tolerance:
            continue

        # Check if word is between CET Form and Gender columns
        if cet_form_x1 < word_x0 < gender_x0:
            # Exclude single letters that might be gender markers
            if len(word_text) > 1 or word_text not in ['M', 'F']:
                name_parts.append((word_x0, word_text))

    # Sort by x-coordinate to maintain word order
    name_parts.sort(key=lambda x: x[0])

    # Join the words to form the full name
    full_name = ' '.join([word for _, word in name_parts])

    return full_name

def separate_college_code_name(college_text):
    """Separate college code and name properly"""
    if not college_text:
        return '', ''

    # Handle format like "1103:GSMC MUMBAI"
    if ':' in college_text:
        parts = college_text.split(':', 1)
        code = parts[0].strip()
        name = parts[1].strip() if len(parts) > 1 else ''
        return code, name

    # If no colon, try to extract numeric code at the beginning
    match = re.match(r'^(\d+)(.+)', college_text)
    if match:
        code = match.group(1)
        name = match.group(2).strip()
        return code, name

    # If no pattern matches, return empty code and full text as name
    return '', college_text

def process_single_page(page_num, pdf_path):
    """Process a single page - designed for parallel execution"""
    page_data = []

    try:
        with pdfplumber.open(pdf_path) as pdf:
            page = pdf.pages[page_num - 1]

            # Extract text and words once
            text = page.extract_text()
            if not text:
                return page_data

            words = page.extract_words()

            # Build word lookup by Sr No for faster y-coordinate finding
            sr_word_map = {}
            for word in words:
                if word['text'].isdigit() and word['x0'] < 100:  # Sr No column
                    sr_word_map[word['text']] = word['top']

            # Build CET Form position map
            cet_form_map = {}
            for word in words:
                if word['text'].isdigit() and 200 < word['x0'] < 300:  # CET Form column
                    cet_form_map[word['text']] = word['x1']

            lines = text.split('\n')

            # Merge multi-line entries (for long college names)
            merged_lines = []
            i = 0
            while i < len(lines):
                line = lines[i]

                # Check if this is a data line
                if re.match(r'^\s*(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+', line):
                    # Check if next line is continuation (doesn't start with number)
                    if i + 1 < len(lines):
                        next_line = lines[i + 1].strip()
                        # If next line doesn't start with digit and is not empty/header
                        if next_line and not re.match(r'^\d+\s+\d+', next_line) and \
                           not any(skip in next_line.upper() for skip in ['SR.', 'AIR', 'LEGENDS', 'GOVERNMENT']):
                            # Merge with next line
                            line = line + ' ' + next_line
                            i += 1  # Skip next line as we merged it
                    merged_lines.append(line)
                else:
                    merged_lines.append(line)
                i += 1

            for line in merged_lines:
                # Skip header/footer lines
                if any(skip in line.upper() for skip in ['SR.', 'AIR', 'NEET', 'LEGENDS',
                                                  'GOVERNMENT', 'PRINTED', 'NOTE:',
                                                  'LAST DATE', 'ADMITTING', '---',
                                                  'PG:', 'CAP ROUND', 'PROVISIONAL',
                                                  'SELECTION LIST', 'MAHARASHTRA',
                                                  'HEALTH SCIENCE']):
                    continue

                # Better regex to catch more variations
                # Looking for: Sr AIR NEET_Roll CET_Form
                match = re.match(r'^\s*(\d+)\s+(\d+)\s+(\d+)\s+(\d+)', line)
                if not match:
                    continue

                sr_no = match.group(1)
                air = match.group(2)
                neet_roll = match.group(3)
                cet_form = match.group(4)

                # Validate Sr No and AIR are reasonable
                try:
                    if int(sr_no) > 100000 or int(air) > 1000000:
                        continue
                except:
                    continue

                # Find y-coordinate from Sr No
                row_y = sr_word_map.get(sr_no)

                if not row_y:
                    # Fallback: search in all words
                    for word in words:
                        if word['text'] == sr_no and word['x0'] < 100:
                            row_y = word['top']
                            break

                if not row_y:
                    continue

                # Get CET Form x1 position
                cet_form_x1 = cet_form_map.get(cet_form, 300)

                # Try to extract name using coordinates first
                name = extract_name_from_coordinates(words, row_y, cet_form_x1, GENDER_X['x0'])

                # If name is empty, try text parsing
                if not name:
                    name = extract_name_from_line(line, cet_form)

                # Use X-COORDINATES for other columns
                gender = extract_column_by_coordinates_fast(words, GENDER_X['x0'], GENDER_X['x1'], row_y)
                category = extract_column_by_coordinates_fast(words, CAT_X['x0'], CAT_X['x1'], row_y)
                quota = extract_column_by_coordinates_fast(words, QUOTA_X['x0'], QUOTA_X['x1'], row_y)

                # Extract college information using coordinates
                college_full = ''
                # First try to get the college code from the specific coordinates
                college_code = extract_column_by_coordinates_fast(words, COLLEGE_CODE_X['x0'], COLLEGE_CODE_X['x1'], row_y)

                # If we got a college code, try to get the college name from the rest of the line
                if college_code:
                    # Get all words after the college code in the same row
                    college_words = []
                    for word in words:
                        if abs(word['top'] - row_y) <= 5 and word['x0'] > COLLEGE_CODE_X['x1']:
                            college_words.append(word['text'])

                    college_full = college_code + ' ' + ' '.join(college_words)
                else:
                    # Fallback: extract college information from the line
                    # Parse the rest of the line to find college information
                    parts = line.split()
                    if len(parts) > 5:
                        # Find gender (M/F) - it should be a single letter
                        gender_idx = -1
                        for i, part in enumerate(parts[4:], 4):
                            if part in ['M', 'F'] and len(part) == 1:
                                gender_idx = i
                                break

                        if gender_idx > 0:
                            # Extract college (everything after gender)
                            remaining = parts[gender_idx + 1:]
                            college_full = ' '.join(remaining)

                # Separate college code and name
                college_code, college_name = separate_college_code_name(college_full)

                # Clean up gender (should be just M or F)
                if gender:
                    gender = gender[0] if gender[0] in ['M', 'F'] else ''

                # Only add if we have at least name and gender
                if name and gender:
                    page_data.append({
                        'Sr. No': sr_no,
                        'AIR': air,
                        'NEET Roll No': neet_roll,
                        'CET Form No': cet_form,
                        'Name': name,
                        'Gender': gender,
                        'Category': category,
                        'Quota': quota,
                        'College Code': college_code,
                        'College Name': college_name,
                        'Page': page_num
                    })

    except Exception as e:
        print(f"Error on page {page_num}: {str(e)}")

    return page_data

# Get total pages
print("\nChecking PDF...")
with pdfplumber.open(pdf_filename) as pdf:
    total_pages = len(pdf.pages)

print(f"Total pages: {total_pages}")
print(f"Starting parallel extraction with multi-threading...\n")

start_time = time.time()

# Process pages in parallel
all_data = []
max_workers = 4  # Adjust based on your system

with ThreadPoolExecutor(max_workers=max_workers) as executor:
    # Submit all pages for processing
    futures = {executor.submit(process_single_page, page_num, pdf_filename): page_num
               for page_num in range(1, total_pages + 1)}

    # Progress bar
    with tqdm(total=total_pages, desc="Processing pages") as pbar:
        for future in as_completed(futures):
            page_data = future.result()
            all_data.extend(page_data)
            pbar.update(1)

end_time = time.time()
processing_time = end_time - start_time

# Create DataFrame
df = pd.DataFrame(all_data)

# Sort by Sr. No
df['Sr. No'] = pd.to_numeric(df['Sr. No'], errors='coerce')
df = df.sort_values('Sr. No').reset_index(drop=True)

# Display results
print(f"\n{'='*70}")
print(f"✓ Extraction completed in {processing_time:.2f} seconds")
print(f"✓ Speed: {total_pages/processing_time:.2f} pages/second")
print(f"✓ Total records extracted: {len(df)}")
print(f"✓ Expected records per page: ~35 rows")
print(f"✓ Total expected (approx): ~{total_pages * 35} rows")
print(f"{'='*70}\n")

print("First 10 records:")
print(df.head(10))

# Check for missing data
print("\n=== Data Quality Check ===")
print(f"Rows with missing Name: {df['Name'].isna().sum() + (df['Name'] == '').sum()}")
print(f"Rows with missing Gender: {df['Gender'].isna().sum() + (df['Gender'] == '').sum()}")
print(f"Rows with missing Category: {df['Category'].isna().sum() + (df['Category'] == '').sum()}")
print(f"Rows with missing Quota: {df['Quota'].isna().sum() + (df['Quota'] == '').sum()}")
print(f"Rows with missing College Code: {df['College Code'].isna().sum() + (df['College Code'] == '').sum()}")
print(f"Rows with missing College Name: {df['College Name'].isna().sum() + (df['College Name'] == '').sum()}")

# Save to Excel
excel_filename = 'NEET_Selection_List_Extracted.xlsx'
print(f"\nSaving to Excel...")
df.to_excel(excel_filename, index=False, engine='openpyxl')

print(f"✓ Data successfully exported to {excel_filename}")

# Download the file
files.download(excel_filename)

# Display summary statistics
print("\n=== Summary Statistics ===")
print(f"Total Candidates: {len(df)}")
if len(df) > 0:
    print(f"\nGender Distribution:")
    print(df['Gender'].value_counts())
    print(f"\nTop 10 Categories:")
    print(df['Category'].value_counts().head(10))
    print(f"\nTop 10 College Codes:")
    print(df['College Code'].value_counts().head(10))
    print(f"\nTop 10 College Names:")
    print(df['College Name'].value_counts().head(10))

print(f"\nProcessing completed! Time taken: {processing_time:.2f} seconds")
print(f"\nIf rows are less than expected, check the Data Quality section above.")